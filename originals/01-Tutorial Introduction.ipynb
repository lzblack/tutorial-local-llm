{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb155d6b-d8e8-469d-ae24-52f8ad975052",
   "metadata": {},
   "source": [
    "# 1 - Tutorial: Introduction to Serving Local LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d1dda9-f687-4fc4-8155-daf1e0a34f4d",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "\n",
    "There are a few background tasks that you should do while we go over the introduction, as they may take 2-5 minutes for your laptop to complete, depending on your current setup and the event WiFi\n",
    "\n",
    "**NOTE 1:** If you haven't completed the setup steps in the [README.md](../README.md) then please do so now -- the Python environment is 1.5-2.5GB and there are 5GB of models to download. [https://github.com/ijstokes/tutorial-local-llm/](https://github.com/ijstokes/tutorial-local-llm/)\n",
    "\n",
    "**NOTE 2:** For everyone who prepared your environment *before* the start of the tutorial, please take two actions now:\n",
    "\n",
    "1. Pull the latest version of the repository, as there may have been some last minute updates:\n",
    "\n",
    "```bash\n",
    "git pull\n",
    "```\n",
    "\n",
    "2. Following that, please update your environment with one of the two commands below depending on whether you use Conda/Mamba or UV:\n",
    "\n",
    "```bash\n",
    "mamba env update -f environment.yml\n",
    "```\n",
    "or\n",
    "```bash\n",
    "uv add -r requirements.txt\n",
    "```\n",
    "\n",
    "**Note 3:** Everyone should have a few terminal windows open, in the tutorial directory, all with the tutorial Python environment activated (see [README.md](../README.md)).  Additionally you should have a Jupyter notebook session up and running **also** using the tutorial Python environment `tutorial-local-llm`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab290e4c-5813-4b9d-89bf-d285bd234c90",
   "metadata": {},
   "source": [
    "## 1.1 Why Run Local LLMs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8369d0-7946-41e9-b731-c0dd5d3e7f6c",
   "metadata": {},
   "source": [
    "Let's discuss why you would consider managing and running your own local LLMs\n",
    "* \n",
    "* \n",
    "* \n",
    "* \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e07c5f3-e484-44d5-9e45-5ec3fbd6f6fc",
   "metadata": {},
   "source": [
    "## 1.2 What are drivers for LLM running costs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003be2ed-b354-4264-99c0-2e0e6f002b05",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
