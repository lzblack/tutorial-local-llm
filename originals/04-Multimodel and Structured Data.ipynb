{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8980bde-0895-4c36-a467-cacc0141e174",
   "metadata": {},
   "source": [
    "# 04 - Multimodal and Structured Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9550a3-1d46-408c-a15a-c1e883d8796d",
   "metadata": {},
   "source": [
    "So far we have only looked at models which exclusively support text input and output, however many models provide a wider range of input and output.  Alternatives to text include:\n",
    "\n",
    "* Image\n",
    "* Video\n",
    "* Audio\n",
    "* JSON\n",
    "\n",
    "We'll now briefly look at ways in which local LLMs can support multi-modal inputs/outputs and structured data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccc5b0e-020b-4124-aaca-fcc1f31225a4",
   "metadata": {},
   "source": [
    "## 4.1 Image analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be2d28e-4cad-46b6-9d36-9f83870e5286",
   "metadata": {},
   "source": [
    "Ollama supports the [LLava class of models](https://llava-vl.github.io/) which allow for image analysis and understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d69f01dc-9922-4e55-9d7f-7a6ece861014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T22:03:42.755299Z",
     "iopub.status.busy": "2025-12-08T22:03:42.754152Z",
     "iopub.status.idle": "2025-12-08T22:03:43.191864Z",
     "shell.execute_reply": "2025-12-08T22:03:43.191344Z",
     "shell.execute_reply.started": "2025-12-08T22:03:42.754834Z"
    }
   },
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "147d948e-b3ed-4b83-884b-4c758120deb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T22:03:43.192335Z",
     "iopub.status.busy": "2025-12-08T22:03:43.192235Z",
     "iopub.status.idle": "2025-12-08T22:03:43.196363Z",
     "shell.execute_reply": "2025-12-08T22:03:43.194124Z",
     "shell.execute_reply.started": "2025-12-08T22:03:43.192308Z"
    }
   },
   "outputs": [],
   "source": [
    "messages=[\n",
    "    dict(role='user',\n",
    "         content='Describe this image',\n",
    "         images=['../img/HF-logo-horizontal.png'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8b6d505-94fb-4a9d-a531-d455eba8d38d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T22:03:44.470689Z",
     "iopub.status.busy": "2025-12-08T22:03:44.470260Z",
     "iopub.status.idle": "2025-12-08T22:03:53.839700Z",
     "shell.execute_reply": "2025-12-08T22:03:53.838431Z",
     "shell.execute_reply.started": "2025-12-08T22:03:44.470656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.74 ms, sys: 10.2 ms, total: 14.9 ms\n",
      "Wall time: 9.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = ollama.chat(\n",
    "\tmodel=\"llava-phi3:3.8b\",\n",
    "\tmessages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f799fb1-691d-424a-9945-de33cd45e363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T22:03:59.751576Z",
     "iopub.status.busy": "2025-12-08T22:03:59.751188Z",
     "iopub.status.idle": "2025-12-08T22:03:59.758492Z",
     "shell.execute_reply": "2025-12-08T22:03:59.757131Z",
     "shell.execute_reply.started": "2025-12-08T22:03:59.751542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image presents a playful and friendly scene. Dominating the center of the black background is a yellow smiley face, its arms stretched out in an open hug. The eyes of the smiley face are filled with joy, adding to the overall cheerful vibe of the image.\n",
      "\n",
      "Just below this heartwarming figure, there's a line of text that reads \"Huggling Face\". The words are written in a blue color and appear to be slightly tilted downwards, creating a dynamic contrast with the upward-facing smiley face above them. The combination of these elements creates a sense of comfort and positivity.\n"
     ]
    }
   ],
   "source": [
    "print(result['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1273039c-cf3d-464a-90f8-343f6b7bea75",
   "metadata": {},
   "source": [
    "### EXERCISE: Use the Llava LLM to analyze the Context Window trend graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72bacdf-0034-4dc9-b4fa-f0836ccd5d2e",
   "metadata": {},
   "source": [
    "*(5 minutes)*\n",
    "\n",
    "Using the same technique, analyze the file in the tutorial repo at this path:\n",
    "\n",
    "`img/meibel-ai-context-window-size-history.png`\n",
    "\n",
    "1. Get a general description\n",
    "2. Ask specific questions about the image\n",
    "3. Ask for the main observations based on the data in the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5532383c-74db-43d0-a39f-eadf14fed473",
   "metadata": {},
   "source": [
    "## 5.2 Structured Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e4ac16-43ae-49c5-a59d-e38effbae683",
   "metadata": {},
   "source": [
    "There are two general mechanisms which help coerce model output into a structured format:\n",
    "\n",
    "* Model trained to produce structured output in a particular format (e.g. [Osmosis 600M](https://huggingface.co/osmosis-ai/Osmosis-Structure-0.6B))\n",
    "* Model wrapped with layer that enforces structured input and/or output\n",
    "\n",
    "Ollama supports [`pydantic`](https://docs.pydantic.dev/latest/) output type definitions, which provides a straight forward way to define your expected outputs.  Some other options include:\n",
    "\n",
    "* [`instructor`](https://useinstructor.com/)\n",
    "* [`outlines`](https://github.com/dottxt-ai/outlines)\n",
    "* [BAML](https://boundaryml.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51f7fae8-b763-487d-b146-1506159cdaa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T22:04:41.490753Z",
     "iopub.status.busy": "2025-12-08T22:04:41.490426Z",
     "iopub.status.idle": "2025-12-08T22:04:41.496431Z",
     "shell.execute_reply": "2025-12-08T22:04:41.494950Z",
     "shell.execute_reply.started": "2025-12-08T22:04:41.490726Z"
    }
   },
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dcbf759-7777-4547-b89b-228ceb919fe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T22:04:44.827076Z",
     "iopub.status.busy": "2025-12-08T22:04:44.826728Z",
     "iopub.status.idle": "2025-12-08T22:04:44.834968Z",
     "shell.execute_reply": "2025-12-08T22:04:44.833324Z",
     "shell.execute_reply.started": "2025-12-08T22:04:44.827050Z"
    }
   },
   "outputs": [],
   "source": [
    "class ChatSession:\n",
    "    def __init__(self,\n",
    "                 model:str,\n",
    "                 format:BaseModel = None,\n",
    "                 system:str = 'You are a helpful chatbot'):\n",
    "        self.model    = model\n",
    "        self.format   = format\n",
    "        self.system   = system\n",
    "        self.messages = []\n",
    "\n",
    "        self.messages.append(dict(role='system', content=system))\n",
    "\n",
    "    def prompt(self, msg) -> str:\n",
    "        self.messages.append(dict(role='user', content=msg))\n",
    "        if self.format:\n",
    "            json_format = self.format.model_json_schema()\n",
    "        else:\n",
    "            json_format = None\n",
    "        raw_response = chat(model=self.model,\n",
    "                        messages=self.messages,\n",
    "                        format=json_format).message.content\n",
    "                            \n",
    "        if self.format:\n",
    "            response = self.format.model_validate_json(raw_response)\n",
    "        else:\n",
    "            response = raw_response\n",
    "            \n",
    "        self.messages.append(dict(role='assistant', content=raw_response))\n",
    "        \n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5badb83-64a5-44e3-bfd2-b46631671b36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T22:05:53.704075Z",
     "iopub.status.busy": "2025-12-08T22:05:53.703854Z",
     "iopub.status.idle": "2025-12-08T22:05:53.709023Z",
     "shell.execute_reply": "2025-12-08T22:05:53.708354Z",
     "shell.execute_reply.started": "2025-12-08T22:05:53.704062Z"
    }
   },
   "outputs": [],
   "source": [
    "class Address(BaseModel):\n",
    "    street: str\n",
    "    city:   str\n",
    "    state:  str\n",
    "    zip:    str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da5c59e3-57d0-4c43-a26d-1296196dff92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T22:05:53.998309Z",
     "iopub.status.busy": "2025-12-08T22:05:53.997474Z",
     "iopub.status.idle": "2025-12-08T22:05:54.004248Z",
     "shell.execute_reply": "2025-12-08T22:05:54.002397Z",
     "shell.execute_reply.started": "2025-12-08T22:05:53.998274Z"
    }
   },
   "outputs": [],
   "source": [
    "cs = ChatSession(model='gemma2:2b', \n",
    "                 format=Address, \n",
    "                 system='Please extract addresses from each prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4d9775-10d2-407f-a81d-15f1ba5d7351",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T22:05:54.847970Z",
     "iopub.status.busy": "2025-12-08T22:05:54.847604Z",
     "iopub.status.idle": "2025-12-08T22:06:03.973526Z",
     "shell.execute_reply": "2025-12-08T22:06:03.972529Z",
     "shell.execute_reply.started": "2025-12-08T22:05:54.847941Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "me = cs.prompt('I live at 123 Washington St, in the city of Syracuse, NY. My zip code is 13444')\n",
    "me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f97b3f44-7b16-4d77-b9e7-73ea46556b0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:39:32.292124Z",
     "iopub.status.busy": "2025-12-09T12:39:32.289194Z",
     "iopub.status.idle": "2025-12-09T12:39:32.342083Z",
     "shell.execute_reply": "2025-12-09T12:39:32.332123Z",
     "shell.execute_reply.started": "2025-12-09T12:39:32.291230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'123 Washington St'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me.street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57a6903b-8783-4e55-acdf-3a8573adcbde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T22:06:11.642870Z",
     "iopub.status.busy": "2025-12-08T22:06:11.641876Z",
     "iopub.status.idle": "2025-12-08T22:06:13.018718Z",
     "shell.execute_reply": "2025-12-08T22:06:13.018388Z",
     "shell.execute_reply.started": "2025-12-08T22:06:11.642803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.58 ms, sys: 4.6 ms, total: 8.18 ms\n",
      "Wall time: 1.37 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Address(street='765 Loyalist Drive', city='Saint John', state='New Brunswick', zip='E2K 5G5')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "parents = cs.prompt('''\n",
    "My parents live in Saint John, New Brunswick.\n",
    "Their street address is 765 Loyalist Drive.\n",
    "Their postal code is E2K 5G5.\n",
    "''')\n",
    "parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1b4eb78-7960-43d1-9cad-79a54d45bde2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:39:45.219246Z",
     "iopub.status.busy": "2025-12-09T12:39:45.218874Z",
     "iopub.status.idle": "2025-12-09T12:39:45.228538Z",
     "shell.execute_reply": "2025-12-09T12:39:45.227561Z",
     "shell.execute_reply.started": "2025-12-09T12:39:45.219218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E2K 5G5'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parents.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df3a2e20-123c-4140-8e28-2ee7266bae80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:40:00.262795Z",
     "iopub.status.busy": "2025-12-09T12:40:00.262322Z",
     "iopub.status.idle": "2025-12-09T12:40:00.277692Z",
     "shell.execute_reply": "2025-12-09T12:40:00.276101Z",
     "shell.execute_reply.started": "2025-12-09T12:40:00.262761Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Address"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41994206-6e4c-4479-8860-2d34253f992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66ecb73-fdce-4faa-8d52-096672fbed02",
   "metadata": {},
   "source": [
    "### EXERCISE: Extract movie review into JSON\n",
    "\n",
    "*(5 minutes)*\n",
    "\n",
    "Using [these short movie reviews](https://letterboxd.com/paragraphfilms/reviews/) use the text content, not including the score, as the prompt input.  Create a Pydantic `MovieReview` model to capture the key elements of the review data, including movie name, year of release, sentiment, summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53900ac-8f24-4757-a3b6-0b6c72b111e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
